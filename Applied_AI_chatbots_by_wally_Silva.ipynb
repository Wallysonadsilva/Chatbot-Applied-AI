{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a25ad07-1ad9-49ce-8eed-be8e44a8655e",
   "metadata": {},
   "source": [
    "<h1>PART A - ChatBots</h1>\n",
    "\n",
    "<h2>What is a chatbot?</h2>\n",
    "\n",
    "A chatbot is a computer program that imitates and handles human conversation, whether written or spoken. It enables people to interact virtually as if talking to a real person, as a consequence replacing the need for an actual representative. Chatbots come in different types, from basic programs that give simple answers to advanced ones, such as digital assistants. These advanced chatbots can learn and become more personalised by gathering and processing information. While not all chatbots use artificial intelligence, modern ones increasingly incorporate conversational AI techniques like natural language processing (NLP) to understand user questions better and automatically generate responses.\n",
    "\n",
    "The first-ever chatbot, called ELIZA, was made by Joseph Weizenbaum in 1966, using substitution methodology and pattern matching to simulate a conversation. The chatbot worked by comparing the input words that users entered into the computer to a set of scripted responses. This set script simulated a psychotherapist.\n",
    "According to Ina (2022, March 15), \"The History of Chatbots\" article. this proved to have a significant impact on natural language processing and unnatural intelligence, with copies and variations of ELIZA starting to be used in academic institutions nationwide.\n",
    "In decades to follow since the creation of ELIZA, chatbot creators have expanded upon Weizenbaum's model, aiming to achieve interactions that are more human-like.\n",
    "\n",
    "Some examples of modern chatbots are Siri, Alexa, Cortana, Bard, and ChatGPT.\n",
    "\n",
    "\n",
    "<h3>AI chatbots can fall into three categories: Rule-based, Hybrid or AI chatbots.</h3>\n",
    "\n",
    "<h5>Rule-based chatbots</h5> present users with predefined options for obtaining answers to specific queries. While these bots provide a restricted range of questions, they prove useful in addressing frequently asked questions (FAQs) from customers.\n",
    "\n",
    "<h5>Hybrid chatbots</h5> combine rule-based functionality with AI technology. They can perform rule-based tasks while also understanding the context and user intent. This makes them a versatile and balanced tool option for business purposes, as they can engage with website visitors effectively. \n",
    " \n",
    "\n",
    "<h2>How has AI been applied to Chatbots?</h2>\n",
    "\n",
    "As mentioned, AI chatbots are software programs that use and understand spoken or written human languages based on NLP. This means that an AI chatbot can detect the intention behind a user's input and provide the most suitable response according to its judgment. However, with machine learning, this AI technology can emulate human-like characteristics, functioning as a problem-solver, engaging in creative thinking, and demonstrating independent reasoning. \n",
    "The more interaction they are exposed to, the more they learn and improve themselves to tackle more significant problems.\n",
    "\n",
    "<h2>How do these chatbots obtain their information?</h2>\n",
    "\n",
    "Their knowledge is built upon utilising Large Language Models(LLMs).\n",
    "LLMs are sophisticated artificial intelligence systems trained on massive datasets containing hundreds of billions of parameters. During this training process, they acquire an extensive understanding of language and the world by recognising patterns embedded in the data.\n",
    "\n",
    "<h3>AI chatbots Techniques</h3>\n",
    "\n",
    "AI chatbots utilise a vast list of techniques to understand user input, generate responses, and provide a coherent conversational experience.\n",
    "Some of the main techniques used in AI chatbots are: \n",
    "\n",
    "1. <h5>Natural Language Processing (NLP)</h5>\n",
    "   - Enables chatbots to understand and interpret human language.\n",
    "     \n",
    "2. <h5>Machine Learning(ML)</h5>\n",
    "   - Allow chatbots to learn from data and improve performance.\n",
    "     \n",
    "3. <h5>Intent Recognition</h5>\n",
    "   - Using ML chatbots can identify the purpose of user input.\n",
    "     \n",
    "4. <h5>Rule-Based Systems</h5>\n",
    "   - It uses predefined sets of rules to guide the chatbots behaviour.\n",
    "     \n",
    "5. <h5>Knowledge Bases</h5>\n",
    "   - Intregrating knowledge bases or databases to chatbots can allow them to provide accurate answers to users queries by accesing information in real-time.\n",
    "     \n",
    "6. <h5>Dialog Management</h5>\n",
    "    - Ensures cohrent and context-aware conversations, often use techiniques like state machines or reinforment learning to manage the interactions and mantain context througout the conversation.\n",
    "      \n",
    "7. <h5>Sentiment Analysis</h5>\n",
    "    - Helps chatbots to better understand the tone of user messages, allowing responses with more empathetic and appropriate interactions.\n",
    "      \n",
    "8. <h5>API Integration</h5>\n",
    "    - Use of external API's can be integrate to chatbots allowing them to access addicionatal services or information such as making transactions, retrieving real-time data, or intereacting with external systems.\n",
    "      \n",
    "9. <h5>Multimodal Capabilities</h5>\n",
    "    - This gives chatbots the capability of processing not only text but also images, voice and other forms of communication.\n",
    "      \n",
    "10. <h5>Continuous Learning</h5>\n",
    "    - With the help of continuous learning mechanims chatbots can adpat and improve over time by analysing new data, user interactions, and feedback to improve their language understanting and responses.\n",
    "      \n",
    "11. <h5>User Context Management</h5>\n",
    "    - This allows chatbot to provide more personalised responses based on the user's history by keeping track of previous interactions and user preferences.\n",
    "\n",
    "Through the combination of these methods, AI chatbots aim to create an interactive, dynamic and user-friendly conversational experience that can undertand and repond to user queries effectively.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80258c93-f5c1-40e9-b3a2-8ab3ef99e4f9",
   "metadata": {},
   "source": [
    "<h1>PART - B</h1>\n",
    "\n",
    "<h2>Goal: Create a chatbot that engages in natural language conversations, providing informative responses and assistance to user queries using information retrieved from a webpage.</h2>\n",
    "\n",
    "<h3>Natural Language Processing</h3>\n",
    "\n",
    "Natural Language Processing (NLP) is a part of artificial intelligence (AI). Its job is to help machines understand and deal with human language so they can perform repetitive tasks independently. Some examples of these tasks include machine translating, detecting sentiment, or speel-checking.\n",
    "\n",
    "\n",
    "Human language is by far very complex, making it challenging for computers to distinguish the true meaning of a sentence. This complexity arises because our linguistic styles can simultaneously display similarities and dissimilarities.\n",
    "\n",
    "For instance:\n",
    "\n",
    "\"I need a break.\"\n",
    "\n",
    "\"I need to break this habit.\"\n",
    "\n",
    "\n",
    "Even though both sentences use the word \"break,\" they mean different things. This complexity adds difficulty for computers to accurately understand the meanings in human language, given the diversity of over 6000 languages spoken worldwide, each with its unique set of rules.\n",
    "\n",
    "In the initial stages of Natural Language Processing, we need to convert it into a computer-understandable format. Using Machine Learning algorithms, NLP recognizes unstructured language and transforms it into meaningful information, facilitating the machine's understanding. This step in NLP is known as data pre-processing.\n",
    "\n",
    "Computers face a significant challenge when using NLP to understand context and tone of voice, especially in cases of sarcasm or irony. Unlike humans who rely on subtle signals, computers find it challenging to interpret the complexities embedded in language accurately. The relationship between words and their context, along with variations in tone, makes it difficult for machines to capture the intended meaning. Sarcasm, for instance, involves saying something but meaning the opposite, a concept that can be challenging for the straightforward algorithms of computers.\n",
    "\n",
    "<h5>How NLP Works?</h5>\n",
    "\n",
    "The functioning of natural language processing involves breaking down human language into smaller fragments. This allows for the analysis of sentence structures and the understanding of word meanings in context. Therefore, computers are enabled to read and understand spoken or written text in the same way as humans.\n",
    "Before NLP tools can make sense of human language, they must go through fundamental pre-processing tasks such as Tokenization, Part-of-speech-tagging, Stemming and lemmatisation, and Stop word removal. Only after that process can the text be transform into something machine can understand.\n",
    "\n",
    "Tokenization: is the process of breaking down a piece of text into smaller chunks, such as words or phrases.\n",
    "\n",
    "Part-of-speech-tagging: it helps computers understand whether a word is a noun, verb, adjective, adverb, pronoun, conjunction, etc.\n",
    "\n",
    "Stemming: is the process that reduces the words into their root/base form. Example: The Stem of the words \"programming\" and \"programmer\" can be reduced to \"program\".\n",
    "\n",
    "lemmatisation: is the process of reducing words to their dictionary form. Example: the verb \"walking\" might appear as \"walking\" and \"walks\".\n",
    "\n",
    "Stop word removal: is the process of removing unnecessary words in a sentence, such as the words \"the\", \"at\", \"a\", \"to\", and others, that don't have much meaning on their own.\n",
    "\n",
    "After completing the pre-processing of the data, the next step is to proceed to building an NLP algorithm. This involves training the algorithm to understand natural language and carry out specific tasks effectively. This algorithm can be created using a Rule-based approach system or Machine Learning. \n",
    "\n",
    "\n",
    "<h3>Machine learning</h3>\n",
    "\n",
    "Machine learning (ML) methods for AI bots can be grouped into two types: goal-oriented and general chatbots. Goal-oriented bots help users solve specific problems, like booking tickets or making reservations. On the other hand, general chatbots engage in conversations on various topics.\n",
    "\n",
    "The most common types of general conversation models are generative and selective (or ranking) models. Hybrid models are also possible. Selective models learn a similarity function to determine how suitable a response is to a given context. The network takes context and a potential response as inputs, calculating a confidence score representing their fitness.\n",
    "\n",
    "In goal-oriented chatbots, the aim is to assist users with specific tasks. These chatbots can be trained through supervised learning, where they learn from real user interactions, or reinforcement learning, where they learn through trial-and-error talks with users.\n",
    "\n",
    "Machine learning chatbots are connected to databases in various applications, helping them operate and respond appropriately. Through natural language processing (NLP), machine learning transforms human language into data, allowing the identification of suitable answers. AI chatbots offer a solution to complex technical problems by creating machines that can closely mimic human interaction and intelligence. \n",
    "\n",
    "However, ML chatbots can encounter a few challenges, such as data dependency, initial training requirements, and difficulty dealing with unforeseen inputs. This means that ML chatbots can potentially give nonsense outputs or be limited in responses and require substantial training data and resources. Training an NLP algorithm, in particular, can be costly and requires access to powerful computing capabilities.\n",
    "\n",
    "ML chatbots also boast some exceptional features. They demonstrate adaptability, adapting over time by talking with the users, helping them to be more responsive to what users want. They are good at solving complex problems, handling difficult tasks, and giving detailed answers when they learn from different sets of examples.\n",
    "Lastly, these chatbots make things personal, using machine-learning techniques and creating individual user profiles collecting information about their preferences and behaviors to customise their answers based on past interactions. This can include the use of natural language processing, enabling chatbots to understand and analyse the context of the user input.\n",
    "\n",
    "\n",
    "<h3>Ruled-Based chatbot</h3>\n",
    "\n",
    "Rule-based chatbots are a type of chatbot that operates on a set of predefined instructions or rules set by the developers. Unlike more sophisticated chatbots that use advanced technologies like machine learning, rule-based chatbots follow a straightforward decision-making process using a set of predefined rules and if-then statements to respond to the user input. This is often done by using keyword matching or simple pattern recognition.\n",
    "\n",
    "These types of chatbots excel in addressing common customer service queries. by operating on a set of preprogrammed rules, they can quickly provide automated responses for various scenarios. This not only accelerates issue resolution but also enhances customer satisfaction. For companies with repetitive customer interactions, these chatbots are incredibly beneficial.\n",
    "\n",
    "Here are some examples of the different types of Rule-based chatbots:\n",
    "\n",
    "Keyword-based Chatbots: They use specific keywords or phrases from the user inputs, relying on a predefined set of keywords and associated rules, enabling them to recognize the user intent and generate the appropriate responses.\n",
    "\n",
    "Buttons-based chatbots: Instead of allowing users to type text, these chatbots rely on predefined buttons or options for user interactions, presenting the user with a set of clickable buttons or menus, guiding them through the conversation and responding accordingly based on the predefined rules associated with each button.\n",
    "\n",
    "Data collection chatbots: These chatbots were designed to gather information or data from the users through conversation interactions or when users follow a predefined path collecting their choice, storing and processing this information for further use. This information can range from personal details and preferences to feedback, survey responses, or any data relevant to the chatbot's purpose.\n",
    "\n",
    "Decision-tree chatbots: A decision-tree chatbot, as the name gives it away, operates on a decision-tree structure, similar to a flowchart structure where each node represents a decision or rule, and the breaches from each node represent the possible outcomes/further decisions. This structure can guide the conversation and make decisions based on the user inputs.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dce827b-e249-4a35-b7a8-cbb25392e157",
   "metadata": {},
   "source": [
    "<h3>Example of Ruled-based chatbot</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f2f227a-6972-4292-8264-9215bdd21c0f",
   "metadata": {},
   "source": [
    "### Install Natural Language Toolkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b7fb5e8-b309-49cf-b8a3-6cd73b8cad2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /Users/w/anaconda3/lib/python3.11/site-packages (3.8.1)\n",
      "Requirement already satisfied: click in /Users/w/anaconda3/lib/python3.11/site-packages (from nltk) (8.0.4)\n",
      "Requirement already satisfied: joblib in /Users/w/anaconda3/lib/python3.11/site-packages (from nltk) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/w/anaconda3/lib/python3.11/site-packages (from nltk) (2022.7.9)\n",
      "Requirement already satisfied: tqdm in /Users/w/anaconda3/lib/python3.11/site-packages (from nltk) (4.65.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08712449-6c72-4700-89b4-267b4000fa00",
   "metadata": {},
   "source": [
    "### Rule-based chatbot example\n",
    "\n",
    "This is an example of a rule-based chatbot for a pizza restaurant scenario, where we predefine all the possible questions and answers.\n",
    "Users can chat with the chatbot, but if the user input does not match the ones in the predefined pair values, it will return \"none\"\n",
    "to close the chat, input the value \"quit\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e9c1477-fdbf-47f1-97da-11a393530736",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You:  quit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversation terminated.\n"
     ]
    }
   ],
   "source": [
    "from nltk.chat.util import Chat, reflections\n",
    "\n",
    "class TerminateChat(Chat):\n",
    "    def converse(self, quit=\"quit\"):\n",
    "        user_input = \"\"\n",
    "        while user_input.lower() != quit.lower():\n",
    "            user_input = input(\"You: \")\n",
    "            if user_input.lower() != quit.lower():\n",
    "                response = self.respond(user_input)\n",
    "                print(\"Chatbot:\", response)\n",
    "        print(\"Conversation terminated.\")\n",
    "\n",
    "pairs = [\n",
    "    ['hello',['hi,how can i help?']],\n",
    "    ['hi',['hi,how can i help?']],\n",
    "    ['I want to order a pizza',['which pizza would you like']],\n",
    "    ['what pizzas you have available?',['this are the available pizza at the moment: Pepperoni, Margarita, Mushroom and Ham']],\n",
    "    ['can i have a pineapple pizza please',['unfortunate and happy we do not have that type of pizza in this restaurant']],\n",
    "    ['Pepperoni',['how many?']],\n",
    "    ['Margarita',['how many?']],\n",
    "    ['Mushroom and ham',['how many?']],\n",
    "    ['2 pepperoni pizzas',['your 2 pepperoni pizzas have being request, it will take a minimum of 35 min']]\n",
    "]\n",
    "\n",
    "chat=TerminateChat(pairs,reflections)\n",
    "chat.converse()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "622e3e90-1c60-4291-8c17-1238ca9d6982",
   "metadata": {},
   "source": [
    "# PART - C"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d4c123e-5170-421d-9af6-ffb43e293fe6",
   "metadata": {},
   "source": [
    "## a. Input required\n",
    "\n",
    "This chatbot implementation relies on user input in a text format. It uses the newspaper3k library to extract data from a webpage. The retrieved data is then processed and divided into a list of sentences using tokenization. Additionally, the chatbot utilises a pre-trained dataset model from nltk (installed in the ruled-base chatbot example). It incorporates natural language processing techniques to understand better the content from the data retrieved. However, without processing the data using these techniques, it would be hard for the chatbot to understand and return the most suitable responses.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14fd3f58-cf65-4540-8ee8-238abfc0fd6c",
   "metadata": {},
   "source": [
    "### Intall newspaper3k Library -  this will allows the system to extract information from website such as article text. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12e41797-8859-4af1-9092-c46d023431ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: newspaper3k in /Users/w/anaconda3/lib/python3.11/site-packages (0.2.8)\n",
      "Requirement already satisfied: beautifulsoup4>=4.4.1 in /Users/w/.local/lib/python3.11/site-packages (from newspaper3k) (4.12.2)\n",
      "Requirement already satisfied: Pillow>=3.3.0 in /Users/w/anaconda3/lib/python3.11/site-packages (from newspaper3k) (10.0.1)\n",
      "Requirement already satisfied: PyYAML>=3.11 in /Users/w/.local/lib/python3.11/site-packages (from newspaper3k) (6.0.1)\n",
      "Requirement already satisfied: cssselect>=0.9.2 in /Users/w/anaconda3/lib/python3.11/site-packages (from newspaper3k) (1.1.0)\n",
      "Requirement already satisfied: lxml>=3.6.0 in /Users/w/anaconda3/lib/python3.11/site-packages (from newspaper3k) (4.9.3)\n",
      "Requirement already satisfied: nltk>=3.2.1 in /Users/w/anaconda3/lib/python3.11/site-packages (from newspaper3k) (3.8.1)\n",
      "Requirement already satisfied: requests>=2.10.0 in /Users/w/.local/lib/python3.11/site-packages (from newspaper3k) (2.31.0)\n",
      "Requirement already satisfied: feedparser>=5.2.1 in /Users/w/anaconda3/lib/python3.11/site-packages (from newspaper3k) (6.0.11)\n",
      "Requirement already satisfied: tldextract>=2.0.1 in /Users/w/anaconda3/lib/python3.11/site-packages (from newspaper3k) (3.2.0)\n",
      "Requirement already satisfied: feedfinder2>=0.0.4 in /Users/w/anaconda3/lib/python3.11/site-packages (from newspaper3k) (0.0.4)\n",
      "Requirement already satisfied: jieba3k>=0.35.1 in /Users/w/anaconda3/lib/python3.11/site-packages (from newspaper3k) (0.35.1)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /Users/w/.local/lib/python3.11/site-packages (from newspaper3k) (2.8.2)\n",
      "Requirement already satisfied: tinysegmenter==0.3 in /Users/w/anaconda3/lib/python3.11/site-packages (from newspaper3k) (0.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/w/.local/lib/python3.11/site-packages (from beautifulsoup4>=4.4.1->newspaper3k) (2.5)\n",
      "Requirement already satisfied: six in /Users/w/.local/lib/python3.11/site-packages (from feedfinder2>=0.0.4->newspaper3k) (1.16.0)\n",
      "Requirement already satisfied: sgmllib3k in /Users/w/anaconda3/lib/python3.11/site-packages (from feedparser>=5.2.1->newspaper3k) (1.0.0)\n",
      "Requirement already satisfied: click in /Users/w/anaconda3/lib/python3.11/site-packages (from nltk>=3.2.1->newspaper3k) (8.0.4)\n",
      "Requirement already satisfied: joblib in /Users/w/anaconda3/lib/python3.11/site-packages (from nltk>=3.2.1->newspaper3k) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/w/anaconda3/lib/python3.11/site-packages (from nltk>=3.2.1->newspaper3k) (2022.7.9)\n",
      "Requirement already satisfied: tqdm in /Users/w/anaconda3/lib/python3.11/site-packages (from nltk>=3.2.1->newspaper3k) (4.65.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/w/.local/lib/python3.11/site-packages (from requests>=2.10.0->newspaper3k) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/w/.local/lib/python3.11/site-packages (from requests>=2.10.0->newspaper3k) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/w/.local/lib/python3.11/site-packages (from requests>=2.10.0->newspaper3k) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/w/.local/lib/python3.11/site-packages (from requests>=2.10.0->newspaper3k) (2023.7.22)\n",
      "Requirement already satisfied: requests-file>=1.4 in /Users/w/anaconda3/lib/python3.11/site-packages (from tldextract>=2.0.1->newspaper3k) (1.5.1)\n",
      "Requirement already satisfied: filelock>=3.0.8 in /Users/w/anaconda3/lib/python3.11/site-packages (from tldextract>=2.0.1->newspaper3k) (3.9.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install newspaper3k"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fcae547-58cf-47d7-8fb2-844661cf9308",
   "metadata": {},
   "source": [
    "### Import libraries used in this project\n",
    "###  sklearn.feature_extraction.text import CountVectorizer -> is a class commonly used to make the analysis of text and natural language processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c54c0125-b547-4b89-b1fd-0216ece87f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from newspaper import Article\n",
    "import random\n",
    "import string\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f2cc22-8590-4763-9e45-1109d1a34071",
   "metadata": {},
   "source": [
    "### Download the punkt package\n",
    "### this function downloads pre-trained dataset models and data needed for nltk sentence and word tokenization functionalities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c92d8a12-c3ce-40c2-a2c7-1525e09a2f75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt', quiet = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b22873fe-84fa-45cf-a476-ae39ab9fbe8f",
   "metadata": {},
   "source": [
    "### Get Article\n",
    "### fetches the website content using the URL, and applies NLP to the data retrieved to understand the content better\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "262de9bd-3255-4373-a392-dbccf5ce050e",
   "metadata": {},
   "outputs": [],
   "source": [
    "article = Article('https://www.britannica.com/science/computer-science')\n",
    "article.download()\n",
    "article.parse()\n",
    "article.nlp()\n",
    "articleText = article.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf599613-d8ff-4f5b-9fb7-d9a603bc3cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this prints the content extracted above and after parsing through the NLP processing. (remove '#' and run)\n",
    "#print(articleText)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e24aab-adc4-4a02-a988-06a458a85290",
   "metadata": {},
   "source": [
    "### Tokenization\n",
    "### This process, as explained in part B, splits the extracted data from the article into individual words, before splitting it into individual words we need first to split it into individual sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d5b87f3c-9b2a-40b6-82eb-5363983dad0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = articleText\n",
    "sentence_list = nltk.sent_tokenize(text)\n",
    "word_list = [word_tokenize(sentence) for sentence in sentence_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e7c2e650-619c-4fcf-a566-e68a52fd3cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this prints the list of sentences after the Tokenization processing.  (remove '#' and run)\n",
    "#print(word_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef670abf-a37d-42f3-9d3a-ff2c0c1df26e",
   "metadata": {},
   "source": [
    "### This function returns a random greeting response to user greetings using a rule-based system and using the random module to choose what greeting to use randomly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c6934842-9b23-4ad0-ba8d-2303de3fecf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def greeting_response(text):\n",
    "    text = text.lower()\n",
    "\n",
    "#bots greeting response\n",
    "    bots_greetings = ['hi', 'hello', 'hello there']\n",
    "#users greetings \n",
    "    user_greetings = ['hi', 'hello', 'hi there']\n",
    "\n",
    "    for word in text.split():\n",
    "        if word in user_greetings:\n",
    "            return random.choice(bots_greetings)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b77cec8-e129-486a-a01d-d02062ad672f",
   "metadata": {},
   "source": [
    "### This function generated a list of indices representing the sorted order of sentences based on their similarity scores. \n",
    "### This function is used in the context of a chatbot to rank responses by their similarity to the user input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bd2340ef-f26f-4be1-97e5-b14f32dab9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_sort(list_var):\n",
    "    length = len(list_var)\n",
    "    list_index = list(range(0, length))\n",
    "\n",
    "    x = list_var\n",
    "    for i in range(length):\n",
    "        for j in range(length):\n",
    "            if x[list_index[i]] > x[list_index[j]]:\n",
    "                temp = list_index[i]\n",
    "                list_index[i] = list_index[j]\n",
    "                list_index[j] = temp\n",
    "\n",
    "    return list_index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0228cdad-da89-441e-9fc5-782017cdbe1f",
   "metadata": {},
   "source": [
    "### Testing example to check the similarity with the text input \"hello\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "26d44e92-60a0-4100-986d-32a1d3f4669a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_sentences(text):\n",
    "    return sent_tokenize(text)\n",
    "    \n",
    "def tokenize_words(sentence):\n",
    "    return word_tokenize(sentence)\n",
    "\n",
    "user_input = \"computer science\"\n",
    "user_words = tokenize_words(user_input)\n",
    "sentence_words = [tokenize_words(sentence) for sentence in sentence_list]\n",
    "all_words = [word for sentence in sentence_words for word in sentence]\n",
    "all_words += user_words\n",
    "updated_sentence_list = [' '.join(words) for words in sentence_words]\n",
    "updated_sentence_list.append(' '.join(user_words))\n",
    "bot_response = ''\n",
    "count_matrix = CountVectorizer().fit_transform(updated_sentence_list)\n",
    "similarity_scores = cosine_similarity(count_matrix[-1], count_matrix)\n",
    "similarity_scores_list = similarity_scores.flatten()\n",
    "index = index_sort(similarity_scores_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cdea9ba-40c4-4356-8c82-c04425c10186",
   "metadata": {},
   "source": [
    "#### If we print the 'similarity_scores_list' we would see the values that match the word \"computer science\"\n",
    "The higher value will be the closest match for the input seach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4b6f9bb3-0024-47f4-8662-3c795659a215",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.375     , 0.22645541, 0.39223227, 0.        , 0.        ,\n",
       "       0.18411492, 0.3086067 , 0.25      , 0.4330127 , 0.35082321,\n",
       "       0.        , 0.15811388, 0.56613852, 0.        , 0.        ,\n",
       "       0.07412493, 0.23249528, 0.31622777, 0.21821789, 0.35355339,\n",
       "       0.50507627, 0.28867513, 0.04693233, 0.09712859, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.23904572, 0.        ,\n",
       "       0.        , 0.15430335, 0.32444284, 0.15075567, 0.        ,\n",
       "       0.        , 0.        , 0.17149859, 0.        , 0.34299717,\n",
       "       0.        , 0.        , 0.        , 0.21566555, 0.25819889,\n",
       "       0.06063391, 0.14433757, 0.        , 0.09712859, 0.        ,\n",
       "       0.33333333, 0.09805807, 0.        , 0.        , 0.        ,\n",
       "       0.38729833, 0.13363062, 0.10660036, 0.12309149, 0.36514837,\n",
       "       0.        , 0.13130643, 0.        , 0.34299717, 0.        ,\n",
       "       0.1767767 , 0.        , 0.        , 0.4472136 , 0.22645541,\n",
       "       0.        , 0.20412415, 0.2300895 , 0.        , 0.        ,\n",
       "       0.        , 0.5547002 , 0.        , 0.09365858, 0.23570226,\n",
       "       0.34757067, 0.22086305, 0.34299717, 0.        , 1.        ])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_scores_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d15749-2f40-44cd-9193-bd2966c53ccf",
   "metadata": {},
   "source": [
    "### If we print the 'index' we can check with one of the sorted values in the 'similarity_score_list' is the most suitable correspondence to the user input\n",
    "This will print the position of the value inside the array; in this case, position 84 corresponds to the last value in the array above (1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d0b8906a-50b9-4f1d-837f-dfc9aeced24f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[84, 12, 76, 20, 68]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d31cbb87-84cb-4388-bd0d-50ae7d5376ca",
   "metadata": {},
   "source": [
    "### Creating the Chatbot's Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "794a8808-f56d-48a8-9e86-be60fcb7246f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bot_response(user_input):\n",
    "    user_input = user_input.lower()\n",
    "    user_words = word_tokenize(user_input.lower())\n",
    "    sentence_list = sent_tokenize(text)\n",
    "    sentence_words = [tokenize_words(sentence) for sentence in sentence_list]\n",
    "    all_words = [word for sentence in sentence_words for word in sentence]\n",
    "    all_words += user_words\n",
    "    updated_sentence_list = [' '.join(words) for words in sentence_words]\n",
    "    updated_sentence_list.append(' '.join(user_words))\n",
    "    bot_response = ''\n",
    "    count_matrix = CountVectorizer().fit_transform(updated_sentence_list)\n",
    "    similarity_scores = cosine_similarity(count_matrix[-1], count_matrix)\n",
    "    similarity_scores_list = similarity_scores.flatten()\n",
    "    index = index_sort(similarity_scores_list)\n",
    "    index = index[1:]\n",
    "    response_flag = 0\n",
    "\n",
    "    j = 0\n",
    "    for i in range(len(index)):\n",
    "        if similarity_scores_list[index[i]] > 0.0:\n",
    "            bot_response += ' ' + updated_sentence_list[index[i]]\n",
    "            response_flag = 1\n",
    "            j += i\n",
    "        if j > 2:\n",
    "            break\n",
    "    \n",
    "    if response_flag == 0:\n",
    "        bot_response += ' ' + \"Sorry, I don't understand.\"\n",
    "\n",
    "    updated_sentence_list.remove(' '.join(user_words))\n",
    "\n",
    "    return bot_response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e824691-fd71-47b2-8f84-7198f23c67fb",
   "metadata": {},
   "source": [
    "### Start chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a283570c-474d-419f-9a27-b85b25f8a5ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatBot: I am your smart bot. I will be helping you with queries about computer science.\n",
      "To close the chat, please type \"close\" or \"exit\".\n",
      "You: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " what are the main concerns of computer science?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot:  The major subfields of computer science include the traditional study of computer architecture , programming languages , and software development . Development of computer science Computer science emerged as an independent discipline in the early 1960s , although the electronic digital computer that is the object of its study was invented some two decades earlier . Many universities across the world offer degrees that teach students the basics of computer science theory and the applications of computer programming .\n",
      "You: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " concerns\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot:  These concerns and others form the basis of social and professional issues of computer science , and they appear in almost all the other fields identified above . Parallel and distributed computing concerns the development of architectures and programming languages that support the development of algorithms whose components can run simultaneously and asynchronously ( rather than sequentially ) , in order to make better use of time and space .\n",
      "You: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " how do I solve a computational problem?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot:  As may be evident , some of these subfields overlap in their activities with other modern fields , such as bioinformatics and computational chemistry . ( more ) Closely related to this field is the design and analysis of systems that interact directly with users who are carrying out various computational tasks . Theoretical work on computability , which began in the 1930s , provided the needed extension of these advances to the design of whole machines ; a milestone was the 1936 specification of the Turing machine ( a theoretical computational model that carries out instructions represented as a series of zeros and ones ) by the British mathematician Alan Turing and his proof of the model ’ s computational power .\n",
      "You: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " algorithm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot:  Computer science applies the principles of mathematics , engineering , and logic to a plethora of functions , including algorithm formulation , software and hardware development , and artificial intelligence .\n",
      "You: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " what is an algorithm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot:  That is , questions such as , “ What can/ can not be computed ? ” have been formally addressed using these abstract ideas . This field of computer science is known as information management . Development of computer science Computer science emerged as an independent discipline in the early 1960s , although the electronic digital computer that is the object of its study was invented some two decades earlier .\n",
      "You: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: See you later! The chat is now closed.\n"
     ]
    }
   ],
   "source": [
    "print('ChatBot: I am your smart bot. I will be helping you with queries about computer science.')\n",
    "print('To close the chat, please type \"close\" or \"exit\".')\n",
    "\n",
    "exit_list = ['close', 'exit']\n",
    "\n",
    "while True:\n",
    "    print(\"You: \")\n",
    "    user_input = input()\n",
    "    if user_input.lower() in exit_list:\n",
    "        print('Chatbot: See you later! The chat is now closed.')\n",
    "        break\n",
    "    else:\n",
    "        greeting_response_result = greeting_response(user_input)\n",
    "        if greeting_response_result is not None:\n",
    "            print('Chatbot: ' + greeting_response_result)\n",
    "        else:\n",
    "            bot_response_result = bot_response(user_input)\n",
    "            print('Chatbot: ' + bot_response_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fac39ab-c4f0-4d46-86e6-425542b56762",
   "metadata": {},
   "source": [
    "### Part D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "844e48bc-a293-4bfa-910b-dc37f204fbfa",
   "metadata": {},
   "source": [
    "I am confident that this prototype effectively addresses the stated problem by retrieving information from the webpage and answering the user queries. However, the accuracy of the answers is not as good as I expected. There is significant room for improvement. Implementing fundamental NLP pre-processing techniques, such as stemming, lemmatisation, and stop-word removal, could significantly enhance its performance.\n",
    "\n",
    "Through the testing processing, I realised that the chatbot performs better when processing shorter or single-word inputs, resulting in more accurate responses. However, it's important to note that even the single-word queries may generate nonsensical replies."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
